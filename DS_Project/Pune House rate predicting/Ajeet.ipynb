{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f16437",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "Real estate transactions are quite opaque sometimes and it may be difficult for a newbie to know the fair price of any given home. Thus, multiple real estate websites have the functionality to predict the prices of houses given different features regarding it. Such forecasting models will help buyers to identify a fair price for the home and also give insights to sellers as to how to build homes that fetch them more money. pune house sale price data is shared here and the participants are expected to build a sale price prediction model that will aid the customers to find a fair price for their homes and also help the sellers understand what factors are fetching more money for the houses?\n",
    "\n",
    "\n",
    "Minimum Requirements It is not sufficient to just fit a model - the model must be analysed to find the important factors that contribute towards the price. Also, it will be better to give a forecast range (range of permissible values) rather than a single estimate as it will help the customers to negotiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv(r\"C:\\Users\\AJEETKUMAR UKANDE\\AJ_PRACTICE FILE\\Project\\Common Projects\\House_Price_Prediction\\Pune_House_Data.csv\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b670ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_exploration():\n",
    "    \n",
    "    def df_info(self):\n",
    "        return df.info()\n",
    "    \n",
    "    def df_shape(self):\n",
    "        print(f'no of rows is:{df.shape[0]}')\n",
    "        print(f'no of features is:{df.shape[1]}')\n",
    "  \n",
    "\n",
    "    def df_head(self):\n",
    "        return df.head()\n",
    "  \n",
    "\n",
    "    def df_dtypes(self):\n",
    "        print('datatypes of features:',df.dtypes.T)\n",
    "  \n",
    "\n",
    "    def df_tail(self):\n",
    "        return df.tail()\n",
    "  \n",
    "\n",
    "    def null_count(self):\n",
    "        for features in df.columns:\n",
    "            is_null=pd.DataFrame(df.isnull().sum()).T\n",
    "            return is_null\n",
    "            print(f'Number of Null values for {features} is:>>{df[features].isna().sum().T}')\n",
    "        \n",
    "    def null_count_perc(self):   \n",
    "        # Get the percentages of null value\n",
    "        null_percent = df.isnull().sum()/df.shape[0]*100\n",
    "        return null_percent\n",
    "\n",
    "  \n",
    "    def int_float_dtype_features(self):\n",
    "        global df_num\n",
    "        df_num=df.select_dtypes(exclude=['object'])\n",
    "        return df_num\n",
    "  \n",
    "\n",
    "    def obj_dtype_features(self):\n",
    "        global df_obj\n",
    "        df_obj=df.select_dtypes(include=['object'])\n",
    "        return df_obj\n",
    "    \n",
    "                \n",
    "    def catog_num_features(self):\n",
    "        print('The data has {} categorical features'.format(len(obj_dtype_features)))\n",
    "        print('The data has {} numerical_features'.format(len(int_float_dtype_features)))\n",
    "  \n",
    "\n",
    "    def value_count(self):\n",
    "        for features in df.columns:\n",
    "            print(\"value_counts are:\",df[[features]].value_counts())\n",
    "#             val_counts=pd.DataFrame(df.dtypes.value_counts()).T\n",
    "#             return val_counts\n",
    "    \n",
    "    def drop_duplicates(self):\n",
    "        global df\n",
    "        n_duplicates = df.drop(labels=[\"id\"], axis=1).duplicated().sum().T\n",
    "        print(f\"You seem to have {n_duplicates} duplicates in your database.\")\n",
    "        columns_to_consider = df.drop(labels=[\"id\"], axis=1).columns\n",
    "        df = df.drop_duplicates(subset=columns_to_consider)\n",
    "             \n",
    "\n",
    "\n",
    "    def df_describes(self):\n",
    "        return df.describe()\n",
    "  \n",
    "  \n",
    "      \n",
    "obj=data_exploration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418341b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d89c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7aaa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df_tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19739f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.value_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.obj_dtype_features().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.int_float_dtype_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36533ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no of int_float_features:\",len(obj.int_float_dtype_features().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no of obj_features:\",len(obj.obj_dtype_features().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total number of features:',df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41882f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.columns:\n",
    "#     print(feature,'',df[feature].isna().sum())\n",
    "    print(f\"{feature : <15}{df[feature].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed433d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['society'].isnull().sum()/df.index([0])*100\n",
    "null_percent_society = df['society'].isnull().sum()/df['society'].shape[0]*100\n",
    "print(\"percentage null count of society is:\",null_percent_society)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null % greater than 40 hence we are plan to drop this features\n",
    "df=df.drop(['society'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be07e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.value_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0638675",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.df_describes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b20818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bathroom having outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_feat=6\n",
    "# num_feat=3\n",
    "# categorial-----area_type,availability,society,site_location>>\n",
    "# size------convert>>into int>>\n",
    "# num-----total_sqft,bath,balcony>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class visualization():\n",
    "    def outliers(self):\n",
    "        for features in df_num:\n",
    "            plt.figure()\n",
    "            print(\"boxplot:,features\",'\\n',df_num[[features]].boxplot())\n",
    "            print(plt.show())\n",
    " \n",
    "\n",
    "\n",
    "    def hist_kde_plot(self):\n",
    "        for features in df_num.columns:\n",
    "            print(\"hist_kde_plot:\",features,'\\n',sns.histplot(df[features],kde=True))\n",
    "            print(plt.show())\n",
    "   \n",
    "\n",
    "    def count_plot(self):    \n",
    "        for features in df_num.columns:\n",
    "            print('plt_fig',plt.figure())\n",
    "        \n",
    "            print(\"countplot:\",features,'\\n',sns.countplot(df_num[features]))\n",
    "            print(plt.show())\n",
    "  \n",
    "\n",
    "    def scatter_plot(self):\n",
    "        print('scatter plot:',sns.pairplot(df))\n",
    "obj=visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24783f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bathroom room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in df_num:\n",
    "#     plt.figure()\n",
    "#     print(\"boxplot:,features\",'\\n',df_num[[feature]].boxplot())\n",
    "#     print(plt.show())\n",
    "# -------------------------------------------------------------------------\n",
    "q3=df['bath'].quantile(0.75)\n",
    "q1=df['bath'].quantile(0.25)\n",
    "iqr=q3-q1\n",
    "upper_limit=q3+1.5*iqr\n",
    "lower_limit=q1-1.5*iqr\n",
    "df['bath']=np.where(df['bath']>upper_limit,df['bath'].median(),df['bath'])\n",
    "# ----------------------------------------------------------------------------\n",
    "plt.figure()\n",
    "print(\"boxplot:,features\",'\\n',df[['bath']].boxplot())\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434421b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ab76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "obj.hist_kde_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d24fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b29dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.count_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('area_type')['area_type'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c30b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('availability')['availability'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1830457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('size')['size'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a221b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('site_location')['site_location'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeaffc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area_type'].unique() #4 uniques>>ordinal data\n",
    "# Plot  Area\n",
    "# Super built-up  Area\n",
    "# Built-up  Area\n",
    "# Carpet  Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'area_type':{'Plot  Area':[3],'Super built-up  Area':[2],'Built-up  Area':[1], 'Carpet  Area':[0]}},inplace=True)\n",
    "df\n",
    "# df.replace({'A': {0: 100, 4: 400}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec27155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# availability\n",
    "df.drop(['availability'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76df9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying median to the balcony and bath column\n",
    "# from math import floor\n",
    "\n",
    "# balcony_median = float(floor(df.balcony.median()))\n",
    "# bath_median = float(floor(df.bath.median()))\n",
    "\n",
    "# df.balcony = df.balcony.fillna(balcony_median)\n",
    "# df.bath = df.bath.fillna(bath_median)\n",
    "# \n",
    "df['balcony']=df['balcony'].fillna(df['balcony'].median())\n",
    "df['bath']=df['bath'].fillna(df['bath'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['size'] = df['size'].apply(lambda x: x.split(' ')[0])\n",
    "# df['size'] = df['size'].astype('int')\n",
    "# from scipy import stats\n",
    "# array_=pd.(df['size'].to_numpy())\n",
    "# size_mode=stats.mode(array_)\n",
    "# df['size']=df['size'].fillna(size_mode)\n",
    "# df['size_bhk']=df['size'].str.split().str.get(0).astype(int)\n",
    "\n",
    "# df[\"BHK\"]=df[\"size\"].fillna(df[\"size\"].median())\n",
    "\n",
    "df['size']=df['size'].fillna('2 BHK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e9cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size_bhk']=df['size'].str.split().str.get(0).astype(int)\n",
    "df=df.drop(['size'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea90834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_sqft'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range convert to mid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_to_mid_value(x):\n",
    "    temp=x.split('-')\n",
    "    if len(temp)==2:\n",
    "        return (float(temp[0])+float(temp[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "df['total_sqft']=df['total_sqft'].apply(range_to_mid_value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec81087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3=df['size_bhk'].quantile(0.75)\n",
    "q1=df['size_bhk'].quantile(0.25)\n",
    "median= df['size_bhk'].quantile(0.50)\n",
    "iqr=q3-q1\n",
    "upper_limit=q3+1.5*iqr\n",
    "lower_limit=q1-1.5*iqr\n",
    "# ---------------------------------------------------------\n",
    "print(median)\n",
    "print(upper_limit)\n",
    "print(lower_limit)\n",
    "# ---------------------------------------------------------\n",
    "df['size_bhk']=np.where(df['size_bhk']>upper_limit,median,df['size_bhk'])\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "print(\"boxplot:,features\",'\\n',df[['size_bhk']].boxplot())\n",
    "print(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_sqft'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_per_sqft']=df['price']*100000/df['total_sqft']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee49677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['site_location'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['site_location'].value_counts().tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['site_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['site_location'].value_counts()\n",
    "# df['site_location'].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a570a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['site_location'].fillna(['Alandi Road'],inplace=True)\n",
    "df['site_location']=df['site_location'].fillna('Laxmi Road')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['site_location']=df['site_location'].apply(lambda x:x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_location_count=df['site_location'].value_counts()\n",
    "site_location_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b00a1",
   "metadata": {},
   "source": [
    "#Ordinal Encoding: We can use Ordinal Encoding provided in Scikit learn class to encode Ordinal features. It #ensures that ordinal nature of the variables is sustained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ord1 = OrdinalEncoder()\n",
    "# fitting encoder\n",
    "ord1.fit([df['site_location']])\n",
    "# transforming the column after fitting\n",
    "df[\"site_location\"]= ord1.fit_transform(df[[\"site_location\"]]) \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db3e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y = df[\"price\"]\n",
    "X = df.drop([\"price\"], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a95129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the DataFrames\n",
    "# train_data = pd.concat([x_train, y_train], join = 'outer', axis = 1)\n",
    "# test_data = pd.concat([x_test, y_test], join = 'outer', axis = 1)\n",
    "# train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff17404",
   "metadata": {},
   "source": [
    "two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations of the features and thus preserve the rank of the values along each feature.\n",
    "\n",
    "Quantile transforms put all features into the same desired distribution based on the formula \\(G^{-1}(F(X))\\) where \\(F\\) is the cumulative distribution function of the feature and \\(G^{-1}\\) the quantile function of the desired output distribution \\(G\\). This formula is using the two following facts: (i) if \\(X\\) is a random variable with a continuous cumulative distribution function \\(F\\) then \\(F(X)\\) is uniformly distributed on \\([0,1]\\); (ii) if \\(U\\) is a random variable with uniform distribution on \\([0,1]\\) then \\(G^{-1}(U)\\) has distribution \\(G\\). By performing a rank transformation, a quantile transform smooths out unusual distributions and is less influenced by outliers than scaling methods. It does, however, distort correlations and distances within and across features.\n",
    "\n",
    "Power transforms are a family of parametric transformations that aim to map data from any distribution to as close to a Gaussian distribution. --> -->\n",
    "<!-- \n",
    ">>> from sklearn.datasets import load_iris\n",
    ">>> from sklearn.model_selection import train_test_split\n",
    ">>> X, y = load_iris(return_X_y=True)\n",
    ">>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    ">>> quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    ">>> X_train_trans = quantile_transformer.fit_transform(X_train)\n",
    ">>> X_test_trans = quantile_transformer.transform(X_test)\n",
    ">>> np.percentile(X_train[:, 0], [0, 25, 50, 75, 100]) \n",
    "array([ 4.3,  5.1,  5.8,  6.5,  7.9]) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a195b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd3380ed",
   "metadata": {},
   "source": [
    "In many modeling scenarios, normality of the features in a dataset is desirable. Power transforms are a family of parametric, monotonic transformations that aim to map data from any distribution to as close to a Gaussian distribution as possible in order to stabilize variance and minimize skewness.\n",
    "\n",
    "PowerTransformer currently provides two such power transformations, the Yeo-Johnson transform and the Box-Cox transform.\n",
    "\n",
    "The Yeo-Johnson transform is given by:\n",
    "\\[\\begin{split}x_i^{(\\lambda)} = \\begin{cases} [(x_i + 1)^\\lambda - 1] / \\lambda & \\text{if } \\lambda \\neq 0, x_i \\geq 0, \\\\[8pt] \\ln{(x_i + 1)} & \\text{if } \\lambda = 0, x_i \\geq 0 \\\\[8pt] -[(-x_i + 1)^{2 - \\lambda} - 1] / (2 - \\lambda) & \\text{if } \\lambda \\neq 2, x_i < 0, \\\\[8pt] - \\ln (- x_i + 1) & \\text{if } \\lambda = 2, x_i < 0 \\end{cases}\\end{split}\\]\n",
    "\n",
    "while the Box-Cox transform is given by:\n",
    "\\[\\begin{split}x_i^{(\\lambda)} = \\begin{cases} \\dfrac{x_i^\\lambda - 1}{\\lambda} & \\text{if } \\lambda \\neq 0, \\\\[8pt] \\ln{(x_i)} & \\text{if } \\lambda = 0, \\end{cases}\\end{split}\\]\n",
    "\n",
    "Box-Cox can only be applied to strictly positive data. In both methods, the transformation is parameterized by \\(\\lambda\\), which is determined through maximum likelihood estimation. Here is an example of using Box-Cox to map samples drawn from a lognormal distribution to a normal distribution:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c04503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf69870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e09392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7897b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7ab5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d765bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58a367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504c0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e8af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d4b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb31dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604fb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecea11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c842b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b5037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3501415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9250110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b82f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d7dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e275e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7dd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10c115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d4233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5cae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8b0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aef809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in df.columns:\n",
    "#     print(feature,'',df[feature].isna().sum())\n",
    "#     print(f\"{feature : <15}{df[feature].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['bath'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b52a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be handle for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['bath'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a61d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['balcony'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['balcony'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c60614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "# df.groupby('area_type')['area_type'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47146a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "# df.groupby('availability')['availability'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea878ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "# df.groupby('size')['size'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd38fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "# df.groupby('site_location')['site_location'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8938631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns of society\n",
    "# df = df.drop('society', axis='columns')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830fc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the null values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf3c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying median to the balcony and bath column\n",
    "# from math import floor\n",
    "\n",
    "# balcony_median = float(floor(df.balcony.median()))\n",
    "# bath_median = float(floor(df.bath.median()))\n",
    "\n",
    "# df.balcony = df.balcony.fillna(balcony_median)\n",
    "# df.bath = df.bath.fillna(bath_median)\n",
    "\n",
    "# Checking the null values in the dataset again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with null values because the dataset is huge as compared to null values.\n",
    "# df = df.dropna()\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2beca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the size column to bhk\n",
    "# df['bhk'] = df['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "# df = df.drop('size', axis='columns')\n",
    "# df.groupby('bhk')['bhk'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the total_sqft contains range values such as 1133-1384, lets filter out these values\n",
    "# def isFloat(x):\n",
    "#     try:\n",
    "#         float(x)\n",
    "#     except:\n",
    "#         return False\n",
    "#     return True\n",
    "\n",
    "# # Displaying all the rows that are not integers\n",
    "# df[~df['total_sqft'].apply(isFloat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509250b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the range values to integer values and removing other types of error\n",
    "# def convert_sqft_to_num(x):\n",
    "#     tokens = x.split('-')\n",
    "#     if len(tokens) == 2:\n",
    "#         return (float(tokens[0])+float(tokens[1]))/2\n",
    "#     try:\n",
    "#         return float(x)\n",
    "#     except:\n",
    "#         return None\n",
    "    \n",
    "# df['new_total_sqft'] = df.total_sqft.apply(convert_sqft_to_num)\n",
    "# df = df.drop('total_sqft', axis='columns')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the rows in new_total_sqft column that hase None values\n",
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column of price_per_sqft\n",
    "# df1 = df.copy()\n",
    "\n",
    "# In our dataset the price column is in Lakhs\n",
    "# df1['price_per_sqft'] = (df1['price']*100000)/df1['new_total_sqft']\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values of 'location' column\n",
    "# locations = list(df['site_location'].unique())\n",
    "# print(len(locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the extra spaces at the end\n",
    "# df1.site_location = df1.site_location.apply(lambda x: x.strip())\n",
    "\n",
    "# Calulating all the unqiue values in 'site_location' column\n",
    "# location_stats = df1.groupby('site_location')['site_location'].agg('count').sort_values(ascending=False)\n",
    "# location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485084c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking locations with less than 10 values\n",
    "# print(len(location_stats[location_stats<=10]), len(df1.site_location.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the locations with less than or equal to 10 occurences to 'other'\n",
    "# locations_less_than_10 = location_stats[location_stats<=10]\n",
    "# \n",
    "# df1.site_location = df1.site_location.apply(lambda x: 'other' if x in locations_less_than_10 else x)\n",
    "# len(df1.site_location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f00ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values in 'availability column'\n",
    "# df1.groupby('availability')['availability'].agg('count').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the dates into Not Ready\n",
    "# dates = df.groupby('availability')['availability'].agg('count').sort_values(ascending=False)\n",
    "\n",
    "# dates_not_ready = dates[dates<10000]\n",
    "# df.availability = df.availability.apply(lambda x: 'Not Ready' if x in dates_not_ready else x)\n",
    "\n",
    "# len(df.availability.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values in 'area_type' column\n",
    "# df1.groupby('area_type')['area_type'].agg('count').sort_values(ascending=False)\n",
    "\n",
    "# Since the column has only few unique values, we don't perform any operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2= df1.copy()\n",
    "# df2= df2.drop('price_per_sqft', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c988a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical_value into numerical_values using get_dummies method\n",
    "# dummy_cols = pd.get_dummies(df2.site_location)\n",
    "# df2 = pd.concat([df2,dummy_cols], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b29e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical_value into numerical_values using get_dummies method\n",
    "# dummy_cols = pd.get_dummies(df2.availability).drop('Not Ready', axis='columns')\n",
    "# df2 = pd.concat([df2,dummy_cols], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c3c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00427afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical_value into numerical_values using get_dummies method\n",
    "# dummy_cols = pd.get_dummies(df2.area_type).drop('Super built-up  Area', axis='columns')\n",
    "# df2 = pd.concat([df2,dummy_cols], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45501466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a621b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.drop(['area_type','availability','site_location'], axis='columns', inplace=True)\n",
    "# df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0e249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be00ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4da9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b7a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c33a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867619f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2266ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d203438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
